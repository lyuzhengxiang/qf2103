{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24605751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"matplotlib\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13bfbcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_by_row(df, row_name, valid_strings):\n",
    "    \"\"\"\n",
    "    Drops columns from a DataFrame if the specified row (by name) does not contain any of the given valid strings.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to process.\n",
    "    row_name (str): The name of the row to check.\n",
    "    valid_strings (list): List of strings to check for.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The filtered DataFrame with columns removed.\n",
    "    \"\"\"\n",
    "    mask = df.loc[df.index[df.index.get_loc(row_name)]].astype(str).apply(lambda x: any(s in x for s in valid_strings))\n",
    "    return df.loc[:, mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a4a53fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BA</th>\n",
       "      <th>CAT</th>\n",
       "      <th>CVX</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>GS</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>JPM</th>\n",
       "      <th>KO</th>\n",
       "      <th>MCD</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>PFE</th>\n",
       "      <th>SOFI</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>UNH</th>\n",
       "      <th>WMT</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>-0.016087</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>-0.002811</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>-0.013538</td>\n",
       "      <td>-0.016508</td>\n",
       "      <td>-0.006606</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>-0.021698</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.011195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>-0.003490</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>0.019721</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>-0.003604</td>\n",
       "      <td>-0.005333</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>-0.015830</td>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>-0.011250</td>\n",
       "      <td>0.024565</td>\n",
       "      <td>-0.003524</td>\n",
       "      <td>-0.024822</td>\n",
       "      <td>-0.006283</td>\n",
       "      <td>-0.004452</td>\n",
       "      <td>-0.014229</td>\n",
       "      <td>0.017113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>-0.001698</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>-0.058910</td>\n",
       "      <td>0.034123</td>\n",
       "      <td>0.024874</td>\n",
       "      <td>0.021094</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>0.014210</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>-0.010809</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>-0.015890</td>\n",
       "      <td>0.011834</td>\n",
       "      <td>-0.129258</td>\n",
       "      <td>-0.039404</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>0.025084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>-0.009054</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.017627</td>\n",
       "      <td>-0.004465</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>-0.012913</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>-0.003824</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>-0.016795</td>\n",
       "      <td>-0.002325</td>\n",
       "      <td>0.019458</td>\n",
       "      <td>-0.009556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.019667</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>0.008483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>-0.003592</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>-0.001364</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>-0.000878</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.014233</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.184070</td>\n",
       "      <td>0.041055</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-10</th>\n",
       "      <td>-0.024399</td>\n",
       "      <td>-0.014465</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>-0.028286</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>-0.009897</td>\n",
       "      <td>-0.035126</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>-0.013499</td>\n",
       "      <td>-0.010425</td>\n",
       "      <td>-0.016128</td>\n",
       "      <td>-0.013302</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>-0.030435</td>\n",
       "      <td>-0.005226</td>\n",
       "      <td>-0.027876</td>\n",
       "      <td>-0.000507</td>\n",
       "      <td>-0.007329</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>-0.003654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-13</th>\n",
       "      <td>-0.010398</td>\n",
       "      <td>-0.002195</td>\n",
       "      <td>-0.008349</td>\n",
       "      <td>0.032238</td>\n",
       "      <td>0.014328</td>\n",
       "      <td>-0.005378</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>0.017931</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>-0.004210</td>\n",
       "      <td>0.012284</td>\n",
       "      <td>-0.019916</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>0.021478</td>\n",
       "      <td>0.038523</td>\n",
       "      <td>-0.015933</td>\n",
       "      <td>0.025484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-14</th>\n",
       "      <td>-0.004790</td>\n",
       "      <td>-0.003209</td>\n",
       "      <td>-0.021032</td>\n",
       "      <td>0.024713</td>\n",
       "      <td>0.009928</td>\n",
       "      <td>-0.007093</td>\n",
       "      <td>0.015126</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>-0.007254</td>\n",
       "      <td>-0.003650</td>\n",
       "      <td>-0.012705</td>\n",
       "      <td>-0.011095</td>\n",
       "      <td>-0.014659</td>\n",
       "      <td>0.030104</td>\n",
       "      <td>-0.017383</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>-0.008118</td>\n",
       "      <td>0.003927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-15</th>\n",
       "      <td>0.019485</td>\n",
       "      <td>0.025347</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.008895</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.030583</td>\n",
       "      <td>0.058431</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>-0.004362</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.025275</td>\n",
       "      <td>-0.001406</td>\n",
       "      <td>0.033436</td>\n",
       "      <td>-0.007220</td>\n",
       "      <td>0.067336</td>\n",
       "      <td>0.077314</td>\n",
       "      <td>-0.000589</td>\n",
       "      <td>0.006040</td>\n",
       "      <td>0.016183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-16</th>\n",
       "      <td>-0.041239</td>\n",
       "      <td>-0.012117</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>-0.013592</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.019130</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.007741</td>\n",
       "      <td>-0.009110</td>\n",
       "      <td>-0.004066</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>-0.019792</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.049680</td>\n",
       "      <td>-0.034206</td>\n",
       "      <td>-0.062316</td>\n",
       "      <td>-0.000438</td>\n",
       "      <td>-0.001705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL      AMZN        BA       CAT       CVX     GOOGL  \\\n",
       "Date                                                                     \n",
       "2024-01-23  0.006631  0.007979 -0.016087  0.000554 -0.002811  0.007167   \n",
       "2024-01-24 -0.003490  0.005433  0.012358  0.006385  0.019721  0.011226   \n",
       "2024-01-25 -0.001698  0.005594 -0.058910  0.034123  0.024874  0.021094   \n",
       "2024-01-26 -0.009054  0.008647  0.017627 -0.004465  0.003829  0.002105   \n",
       "2024-01-29 -0.003592  0.013359 -0.001364  0.012677 -0.000402  0.008636   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2025-01-10 -0.024399 -0.014465  0.001396 -0.028286  0.018719 -0.009897   \n",
       "2025-01-13 -0.010398 -0.002195 -0.008349  0.032238  0.014328 -0.005378   \n",
       "2025-01-14 -0.004790 -0.003209 -0.021032  0.024713  0.009928 -0.007093   \n",
       "2025-01-15  0.019485  0.025347 -0.004922  0.008895  0.009073  0.030583   \n",
       "2025-01-16 -0.041239 -0.012117  0.016293  0.014985  0.006610 -0.013592   \n",
       "\n",
       "                  GS       JNJ       JPM        KO       MCD      MSFT  \\\n",
       "Date                                                                     \n",
       "2024-01-23 -0.013538 -0.016508 -0.006606  0.004689  0.005481  0.006009   \n",
       "2024-01-24 -0.003604 -0.005333  0.008896 -0.015830  0.001299  0.009133   \n",
       "2024-01-25  0.008660  0.003767  0.014210  0.004235 -0.010809  0.005722   \n",
       "2024-01-26 -0.012913 -0.000376 -0.003824  0.003543 -0.016795 -0.002325   \n",
       "2024-01-29  0.007305 -0.000878  0.002609  0.006045  0.000171  0.014233   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2025-01-10 -0.035126 -0.001477 -0.013499 -0.010425 -0.016128 -0.013302   \n",
       "2025-01-13  0.005254  0.016822  0.017931  0.009453  0.004665 -0.004210   \n",
       "2025-01-14  0.015126  0.001936  0.013261  0.006306 -0.007254 -0.003650   \n",
       "2025-01-15  0.058431  0.001519  0.019528 -0.004362  0.002554  0.025275   \n",
       "2025-01-16  0.011601  0.019130  0.007580  0.007741 -0.009110 -0.004066   \n",
       "\n",
       "                 NKE      NVDA       PFE      SOFI      TSLA       UNH  \\\n",
       "Date                                                                     \n",
       "2024-01-23  0.013237  0.003664  0.004230 -0.021698  0.001627  0.004920   \n",
       "2024-01-24 -0.011250  0.024565 -0.003524 -0.024822 -0.006283 -0.004452   \n",
       "2024-01-25  0.000099  0.004147 -0.015890  0.011834 -0.129258 -0.039404   \n",
       "2024-01-26  0.019458 -0.009556  0.000000 -0.003929  0.003389  0.019667   \n",
       "2024-01-29  0.010937  0.023224  0.000364  0.184070  0.041055  0.002659   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2025-01-10 -0.001263 -0.030435 -0.005226 -0.027876 -0.000507 -0.007329   \n",
       "2025-01-13  0.012284 -0.019916  0.002990 -0.005670  0.021478  0.038523   \n",
       "2025-01-14 -0.012705 -0.011095 -0.014659  0.030104 -0.017383  0.004793   \n",
       "2025-01-15 -0.001406  0.033436 -0.007220  0.067336  0.077314 -0.000589   \n",
       "2025-01-16  0.000563 -0.019792  0.010245  0.049680 -0.034206 -0.062316   \n",
       "\n",
       "                 WMT       XOM  \n",
       "Date                            \n",
       "2024-01-23  0.002522  0.011195  \n",
       "2024-01-24 -0.014229  0.017113  \n",
       "2024-01-25  0.014474  0.025084  \n",
       "2024-01-26  0.008743  0.008483  \n",
       "2024-01-29  0.004676  0.001261  \n",
       "...              ...       ...  \n",
       "2025-01-10  0.012987 -0.003654  \n",
       "2025-01-13 -0.015933  0.025484  \n",
       "2025-01-14 -0.008118  0.003927  \n",
       "2025-01-15  0.006040  0.016183  \n",
       "2025-01-16 -0.000438 -0.001705  \n",
       "\n",
       "[248 rows x 20 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'Trading_Project_Data.csv'\n",
    "\n",
    "df = pd.read_csv(filename,\n",
    "                  index_col = 0,\n",
    "                    )\n",
    "\n",
    "\n",
    "df = df.drop('Date')\n",
    "df.index.name = 'Date'\n",
    "\n",
    "tickers = df.iloc[0]\n",
    "df.columns = [f\"{tickers[col]}_{col.split('.')[0]}\" for col in df.columns]\n",
    "df = df.drop('Ticker')\n",
    "\n",
    "df.index = pd.to_datetime(df.index, dayfirst=True)\n",
    "df = df.dropna()\n",
    "df.head()\n",
    "\n",
    "df = df.astype(float)\n",
    "\n",
    "data = df.loc[:, df.columns.str.contains('Close', case=False)].copy()\n",
    "data.columns = [col.split('_')[0] if ('Close' in col and '_' in col) else col for col in data.columns]\n",
    "data = np.log(data/data.shift(1)).dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba44cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_regression_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    # Convert start_date to datetime and find the index where it occurs\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "    # Determine the rolling window size as the length of rows before the start date\n",
    "    window = start_index  # This will be the number of rows before start_date\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        # Combine features and target\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "        # Determine the rolling window size as the length of rows before the start date\n",
    "        window = start_index  # This will be the number of rows before start_date\n",
    "\n",
    "        for i in range(window, len(full_data)):\n",
    "            window_data = full_data.iloc[i - window:i]\n",
    "            X = window_data[[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = window_data[col]\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "\n",
    "            # Convert prediction to trading signal: 1 or -1\n",
    "            signal = 1 if pred > 0 else -1\n",
    "\n",
    "            # Multiply signal with actual log return to get predicted returns\n",
    "            predicted_returns.loc[pred_index, col] = signal * df.loc[pred_index, col]\n",
    "\n",
    "    # Filter by start_date\n",
    "    predicted_returns = predicted_returns[predicted_returns.index >= pd.to_datetime(start_date)]\n",
    "\n",
    "    return predicted_returns.astype(float)\n",
    "\n",
    "\n",
    "def rolling_DTclassification_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "    window = start_index  # Window size is the number of rows before start_date\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        # Combine features and target\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "        # Determine the rolling window size as the length of rows before the start date\n",
    "        window = start_index  # This will be the number of rows before start_date\n",
    "        \n",
    "        # Create the target: 1 if return is positive, -1 if return is negative\n",
    "        target = np.where(full_data[col] > 0, 1, -1)  # Binary target for classification\n",
    "\n",
    "        for i in range(window, len(full_data)):\n",
    "            window_data = full_data.iloc[i - window:i]\n",
    "            X = window_data[[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = target[i - window:i]  # Use binary target for classification\n",
    "\n",
    "            # Using DecisionTreeClassifier\n",
    "            model = DecisionTreeClassifier(max_depth = 5, random_state = 100)\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "\n",
    "            # Multiply signal with actual log return to get predicted returns\n",
    "            predicted_returns.loc[pred_index, col] = pred * df.loc[pred_index, col]\n",
    "\n",
    "    # Filter by start_date\n",
    "    predicted_returns = predicted_returns[predicted_returns.index >= pd.to_datetime(start_date)]\n",
    "\n",
    "    return predicted_returns.astype(float)\n",
    "\n",
    "\n",
    "def rolling_MLPclassification_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "    window = start_index  # Window size is the number of rows before start_date\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        # Combine features and target\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "        # Determine the rolling window size as the length of rows before the start date\n",
    "        window = start_index  # This will be the number of rows before start_date\n",
    "        \n",
    "        # Create the target: 1 if return is positive, -1 if return is negative\n",
    "        target = np.where(full_data[col] > 0, 1, -1)  # Binary target for classification\n",
    "\n",
    "        for i in range(window, len(full_data)):\n",
    "            window_data = full_data.iloc[i - window:i]\n",
    "            X = window_data[[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = target[i - window:i]  # Use binary target for classification\n",
    "\n",
    "            # Using MLPClassifier\n",
    "            model = MLPClassifier(hidden_layer_sizes = 4 * [15], max_iter = 2000, random_state=100)\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "\n",
    "            # Multiply signal with actual log return to get predicted returns\n",
    "            predicted_returns.loc[pred_index, col] = pred * df.loc[pred_index, col]\n",
    "\n",
    "    # Filter by start_date\n",
    "    predicted_returns = predicted_returns[predicted_returns.index >= pd.to_datetime(start_date)]\n",
    "\n",
    "    return predicted_returns.astype(float)\n",
    "\n",
    "\n",
    "def rolling_svc_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "    window = start_index  # Use all data before the start_date as training window\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        # Combine features and target\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "        # Determine the rolling window size as the length of rows before the start date\n",
    "        window = start_index  # This will be the number of rows before start_date\n",
    "        \n",
    "        # Create binary classification target\n",
    "        target = np.where(full_data[col] > 0, 1, -1)\n",
    "\n",
    "        for i in range(window, len(full_data)):\n",
    "            window_data = full_data.iloc[i - window:i]\n",
    "            X = window_data[[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = target[i - window:i]\n",
    "\n",
    "            model = SVC(kernel='linear')\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "\n",
    "            # Predicted return = signal * actual return\n",
    "            predicted_returns.loc[pred_index, col] = pred * df.loc[pred_index, col]\n",
    "\n",
    "    # Filter rows after the start_date\n",
    "    predicted_returns = predicted_returns[predicted_returns.index >= pd.to_datetime(start_date)]\n",
    "\n",
    "    return predicted_returns.astype(float)\n",
    "\n",
    "\n",
    "def rolling_logistic_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "    window = start_index  # Use all data before the start_date\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        # Combine features and target\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "        # Determine the rolling window size as the length of rows before the start date\n",
    "        window = start_index  # This will be the number of rows before start_date\n",
    "        \n",
    "        # Binary target: 1 for up, -1 for down\n",
    "        target = np.where(full_data[col] > 0, 1, -1)\n",
    "\n",
    "        for i in range(window, len(full_data)):\n",
    "            window_data = full_data.iloc[i - window:i]\n",
    "            X = window_data[[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = target[i - window:i]\n",
    "\n",
    "            # Logistic Regression model\n",
    "            model = LogisticRegression(random_state=100)\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "\n",
    "            # Multiply predicted signal (1/-1) with actual log return\n",
    "            predicted_returns.loc[pred_index, col] = pred * df.loc[pred_index, col]\n",
    "\n",
    "    # Keep only rows after start_date\n",
    "    predicted_returns = predicted_returns[predicted_returns.index >= pd.to_datetime(start_date)]\n",
    "\n",
    "    return predicted_returns.astype(float)\n",
    "\n",
    "\n",
    "def benchmark_returns(df, start_date='2024-03-01'):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # Convert start_date to datetime\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "\n",
    "    # Filter the data from the start_date to the end of the dataset\n",
    "    filtered_data = df[df.index >= start_date]\n",
    "\n",
    "    # Sum the returns for each column from start_date to the end\n",
    "    column_sums = filtered_data.sum(axis=0)\n",
    "\n",
    "    # Apply np.exp to the sum of each column's returns\n",
    "    exp_column_sums = np.exp(column_sums)\n",
    "\n",
    "    return exp_column_sums\n",
    "\n",
    "\n",
    "def sum_and_exp_predicted_returns(predicted_returns):\n",
    "    # Sum each column of the predicted returns DataFrame\n",
    "    column_sums = predicted_returns.sum(axis=0)\n",
    "    \n",
    "    # Apply np.exp to the sum of each column\n",
    "    exp_column_sums = np.exp(column_sums)\n",
    "    \n",
    "    return exp_column_sums\n",
    "\n",
    "\n",
    "def highlight_max_row(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca9948",
   "metadata": {},
   "source": [
    "2 LAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fe0f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy time series data\n",
    "sd = '2024-03-01'\n",
    "lg = [1, 2]\n",
    "\n",
    "\n",
    "LR_preds = rolling_regression_predicted_returns(data,lg,sd)\n",
    "Log_preds = rolling_logistic_predicted_returns(data,lg,sd)\n",
    "DT_preds = rolling_DTclassification_predicted_returns(data,lg,sd)\n",
    "MLP_preds = rolling_MLPclassification_predicted_returns(data,lg,sd)\n",
    "SVC_preds = rolling_svc_predicted_returns(data,lg,sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "913bfb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = benchmark_returns(data)\n",
    "LR_preds_Sum = sum_and_exp_predicted_returns(LR_preds)\n",
    "Log_preds_Sum = sum_and_exp_predicted_returns(Log_preds)\n",
    "DT_preds_Sum = sum_and_exp_predicted_returns(DT_preds)\n",
    "MLP_preds_Sum = sum_and_exp_predicted_returns(MLP_preds)\n",
    "SVC_preds_Sum = sum_and_exp_predicted_returns(SVC_preds)\n",
    "\n",
    "\n",
    "# Merge both series into a DataFrame\n",
    "merged_df = pd.concat([benchmarks, LR_preds_Sum,Log_preds_Sum, DT_preds_Sum, MLP_preds_Sum, SVC_preds_Sum], axis=1)\n",
    "merged_df.columns = ['Benchmark', 'LinReg','Logistic', 'DecisionTree', 'DNN', 'SVC' ]\n",
    "\n",
    "# Apply styling\n",
    "styled_df_roll2 = merged_df.add_suffix('_Roll_2')\n",
    "# styled_df_roll2 = styled_df_roll2.style.apply(highlight_max_row, axis=1)\n",
    "# styled_df_roll2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c95dbc",
   "metadata": {},
   "source": [
    "3 LAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d08a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy time series data\n",
    "sd = '2024-03-01'\n",
    "lg = [1, 2, 3]\n",
    "\n",
    "\n",
    "LR_preds = rolling_regression_predicted_returns(data,lg,sd)\n",
    "Log_preds = rolling_logistic_predicted_returns(data,lg,sd)\n",
    "DT_preds = rolling_DTclassification_predicted_returns(data,lg,sd)\n",
    "MLP_preds = rolling_MLPclassification_predicted_returns(data,lg,sd)\n",
    "SVC_preds = rolling_svc_predicted_returns(data,lg,sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3248429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = benchmark_returns(data)\n",
    "LR_preds_Sum = sum_and_exp_predicted_returns(LR_preds)\n",
    "Log_preds_Sum = sum_and_exp_predicted_returns(Log_preds)\n",
    "DT_preds_Sum = sum_and_exp_predicted_returns(DT_preds)\n",
    "MLP_preds_Sum = sum_and_exp_predicted_returns(MLP_preds)\n",
    "SVC_preds_Sum = sum_and_exp_predicted_returns(SVC_preds)\n",
    "\n",
    "\n",
    "# Merge both series into a DataFrame\n",
    "merged_df = pd.concat([benchmarks, LR_preds_Sum,Log_preds_Sum, DT_preds_Sum, MLP_preds_Sum, SVC_preds_Sum], axis=1)\n",
    "merged_df.columns = ['Benchmark', 'LinReg','Logistic', 'DecisionTree', 'DNN', 'SVC' ]\n",
    "\n",
    "# Apply styling\n",
    "styled_df_roll3 = merged_df.add_suffix('_Roll_3')\n",
    "# styled_df_roll3 = styled_df_roll3.style.apply(highlight_max_row, axis=1)\n",
    "# styled_df_roll3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28285c0",
   "metadata": {},
   "source": [
    "Expanding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4b03a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_regression_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "        for i in range(start_index, len(full_data)):\n",
    "            X = full_data.iloc[:i][[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = full_data.iloc[:i][col]\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "            signal = 1 if pred > 0 else -1\n",
    "\n",
    "            predicted_returns.loc[pred_index, col] = signal * df.loc[pred_index, col]\n",
    "\n",
    "    return predicted_returns[predicted_returns.index >= start_date].astype(float)\n",
    "\n",
    "\n",
    "def expanding_DTclassification_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "        target = np.where(full_data[col] > 0, 1, -1)\n",
    "\n",
    "        for i in range(start_index, len(full_data)):\n",
    "            X = full_data.iloc[:i][[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = target[:i]\n",
    "\n",
    "            model = DecisionTreeClassifier(max_depth=5, random_state=100)\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "\n",
    "            predicted_returns.loc[pred_index, col] = pred * df.loc[pred_index, col]\n",
    "\n",
    "    return predicted_returns[predicted_returns.index >= start_date].astype(float)\n",
    "\n",
    "\n",
    "def expanding_MLPclassification_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "        target = np.where(full_data[col] > 0, 1, -1)\n",
    "\n",
    "        for i in range(start_index, len(full_data)):\n",
    "            X = full_data.iloc[:i][[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = target[:i]\n",
    "\n",
    "            model = MLPClassifier(hidden_layer_sizes = 4 * [15], max_iter = 2000, random_state=100)\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "\n",
    "            predicted_returns.loc[pred_index, col] = pred * df.loc[pred_index, col]\n",
    "\n",
    "    return predicted_returns[predicted_returns.index >= start_date].astype(float)\n",
    "\n",
    "\n",
    "def expanding_svc_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "        target = np.where(full_data[col] > 0, 1, -1)\n",
    "\n",
    "        for i in range(start_index, len(full_data)):\n",
    "            X = full_data.iloc[:i][[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = target[:i]\n",
    "\n",
    "            model = SVC(kernel='linear')\n",
    "            model.fit(X, y)\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "\n",
    "            predicted_returns.loc[pred_index, col] = pred * df.loc[pred_index, col]\n",
    "\n",
    "    return predicted_returns[predicted_returns.index >= start_date].astype(float)\n",
    "\n",
    "\n",
    "def expanding_Logistic_predicted_returns(df, lags=[1, 2], start_date='2024-03-01'):\n",
    "    predicted_returns = pd.DataFrame(index=df.index, columns=df.columns)\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    start_index = df.index.get_indexer([start_date], method='ffill')[0]\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        # Create lagged features\n",
    "        lagged_data = pd.concat([series.shift(lag) for lag in lags], axis=1)\n",
    "        lagged_data.columns = [f'{col}_lag{lag}' for lag in lags]\n",
    "\n",
    "        full_data = pd.concat([series, lagged_data], axis=1).dropna()\n",
    "        start_index = full_data.index.get_indexer([start_date], method='ffill')[0]\n",
    "        target = np.where(full_data[col] > 0, 1, -1)\n",
    "\n",
    "        for i in range(start_index, len(full_data)):\n",
    "            X = full_data.iloc[:i][[f'{col}_lag{lag}' for lag in lags]]\n",
    "            y = target[:i]\n",
    "\n",
    "            model = LogisticRegression(random_state=100)\n",
    "            model.fit(X, y)\n",
    "            model.fit(X, y)\n",
    "\n",
    "            current_features = full_data.iloc[i][[f'{col}_lag{lag}' for lag in lags]].to_frame().T\n",
    "            pred_index = full_data.index[i]\n",
    "            pred = model.predict(current_features)[0]\n",
    "\n",
    "            predicted_returns.loc[pred_index, col] = pred * df.loc[pred_index, col]\n",
    "\n",
    "    return predicted_returns[predicted_returns.index >= start_date].astype(float)\n",
    "\n",
    "\n",
    "def benchmark_returns(df, start_date='2024-03-01'):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    # Convert start_date to datetime\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "\n",
    "    # Filter the data from the start_date to the end of the dataset\n",
    "    filtered_data = df[df.index >= start_date]\n",
    "\n",
    "    # Sum the returns for each column from start_date to the end\n",
    "    column_sums = filtered_data.sum(axis=0)\n",
    "\n",
    "    # Apply np.exp to the sum of each column's returns\n",
    "    exp_column_sums = np.exp(column_sums)\n",
    "\n",
    "    return exp_column_sums\n",
    "\n",
    "\n",
    "def sum_and_exp_predicted_returns(predicted_returns):\n",
    "    # Sum each column of the predicted returns DataFrame\n",
    "    column_sums = predicted_returns.sum(axis=0)\n",
    "    \n",
    "    # Apply np.exp to the sum of each column\n",
    "    exp_column_sums = np.exp(column_sums)\n",
    "    \n",
    "    return exp_column_sums\n",
    "\n",
    "\n",
    "def highlight_max_row(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b4d82",
   "metadata": {},
   "source": [
    "# 3 Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bad3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy time series data\n",
    "sd = '2024-03-01'\n",
    "lg = [1, 2, 3]\n",
    "\n",
    "\n",
    "LR_preds = expanding_regression_predicted_returns(data,lg,sd)\n",
    "Log_preds = expanding_Logistic_predicted_returns(data,lg,sd)\n",
    "DT_preds = expanding_DTclassification_predicted_returns(data,lg,sd)\n",
    "MLP_preds = expanding_MLPclassification_predicted_returns(data,lg,sd)\n",
    "SVC_preds = expanding_svc_predicted_returns(data,lg,sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ae366d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = benchmark_returns(data)\n",
    "LR_preds_Sum = sum_and_exp_predicted_returns(LR_preds)\n",
    "Log_preds_Sum = sum_and_exp_predicted_returns(Log_preds)\n",
    "DT_preds_Sum = sum_and_exp_predicted_returns(DT_preds)\n",
    "MLP_preds_Sum = sum_and_exp_predicted_returns(MLP_preds)\n",
    "SVC_preds_Sum = sum_and_exp_predicted_returns(SVC_preds)\n",
    "\n",
    "\n",
    "# Merge both series into a DataFrame\n",
    "merged_df = pd.concat([benchmarks, LR_preds_Sum,Log_preds_Sum, DT_preds_Sum, MLP_preds_Sum, SVC_preds_Sum], axis=1)\n",
    "merged_df.columns = ['Benchmark', 'LinReg','Logistic', 'DecisionTree', 'DNN', 'SVC' ]\n",
    "\n",
    "# Apply styling\n",
    "styled_df_exp3 = merged_df.add_suffix('_Exp_3')\n",
    "# styled_df_exp3 = styled_df_exp3.style.apply(highlight_max_row, axis=1)\n",
    "# styled_df_exp3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d9e2c",
   "metadata": {},
   "source": [
    "# 2 Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7adda743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy time series data\n",
    "sd = '2024-03-01'\n",
    "lg = [1, 2]\n",
    "\n",
    "\n",
    "LR_preds = expanding_regression_predicted_returns(data,lg,sd)\n",
    "Log_preds = expanding_Logistic_predicted_returns(data,lg,sd)\n",
    "DT_preds = expanding_DTclassification_predicted_returns(data,lg,sd)\n",
    "MLP_preds = expanding_MLPclassification_predicted_returns(data,lg,sd)\n",
    "SVC_preds = expanding_svc_predicted_returns(data,lg,sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3c1ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = benchmark_returns(data)\n",
    "LR_preds_Sum = sum_and_exp_predicted_returns(LR_preds)\n",
    "Log_preds_Sum = sum_and_exp_predicted_returns(Log_preds)\n",
    "DT_preds_Sum = sum_and_exp_predicted_returns(DT_preds)\n",
    "MLP_preds_Sum = sum_and_exp_predicted_returns(MLP_preds)\n",
    "SVC_preds_Sum = sum_and_exp_predicted_returns(SVC_preds)\n",
    "\n",
    "\n",
    "# Merge both series into a DataFrame\n",
    "merged_df = pd.concat([benchmarks, LR_preds_Sum,Log_preds_Sum, DT_preds_Sum, MLP_preds_Sum, SVC_preds_Sum], axis=1)\n",
    "merged_df.columns = ['Benchmark', 'LinReg','Logistic', 'DecisionTree', 'DNN', 'SVC' ]\n",
    "\n",
    "# Apply styling\n",
    "styled_df_exp2 = merged_df.add_suffix('_Exp_2')\n",
    "# styled_df_exp2 = styled_df_exp2.style.apply(highlight_max_row, axis=1)\n",
    "# styled_df_exp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18d1cc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2529b_row0_col0, #T_2529b_row1_col2, #T_2529b_row2_col5, #T_2529b_row3_col0, #T_2529b_row4_col5, #T_2529b_row5_col7, #T_2529b_row6_col0, #T_2529b_row7_col5, #T_2529b_row8_col0, #T_2529b_row9_col4, #T_2529b_row10_col3, #T_2529b_row11_col3, #T_2529b_row12_col6, #T_2529b_row13_col1, #T_2529b_row14_col0, #T_2529b_row15_col0, #T_2529b_row16_col0, #T_2529b_row17_col5, #T_2529b_row18_col0, #T_2529b_row19_col2 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2529b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2529b_level0_col0\" class=\"col_heading level0 col0\" >Benchmark_Roll_2</th>\n",
       "      <th id=\"T_2529b_level0_col1\" class=\"col_heading level0 col1\" >LinReg_Roll_2</th>\n",
       "      <th id=\"T_2529b_level0_col2\" class=\"col_heading level0 col2\" >DecisionTree_Roll_2</th>\n",
       "      <th id=\"T_2529b_level0_col3\" class=\"col_heading level0 col3\" >LinReg_Roll_3</th>\n",
       "      <th id=\"T_2529b_level0_col4\" class=\"col_heading level0 col4\" >Logistic_Roll_3</th>\n",
       "      <th id=\"T_2529b_level0_col5\" class=\"col_heading level0 col5\" >DecisionTree_Roll_3</th>\n",
       "      <th id=\"T_2529b_level0_col6\" class=\"col_heading level0 col6\" >DNN_Roll_3</th>\n",
       "      <th id=\"T_2529b_level0_col7\" class=\"col_heading level0 col7\" >SVC_Roll_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row0\" class=\"row_heading level0 row0\" >AAPL</th>\n",
       "      <td id=\"T_2529b_row0_col0\" class=\"data row0 col0\" >1.267419</td>\n",
       "      <td id=\"T_2529b_row0_col1\" class=\"data row0 col1\" >0.754734</td>\n",
       "      <td id=\"T_2529b_row0_col2\" class=\"data row0 col2\" >0.954708</td>\n",
       "      <td id=\"T_2529b_row0_col3\" class=\"data row0 col3\" >0.870786</td>\n",
       "      <td id=\"T_2529b_row0_col4\" class=\"data row0 col4\" >1.117342</td>\n",
       "      <td id=\"T_2529b_row0_col5\" class=\"data row0 col5\" >0.710308</td>\n",
       "      <td id=\"T_2529b_row0_col6\" class=\"data row0 col6\" >1.054113</td>\n",
       "      <td id=\"T_2529b_row0_col7\" class=\"data row0 col7\" >1.117342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row1\" class=\"row_heading level0 row1\" >AMZN</th>\n",
       "      <td id=\"T_2529b_row1_col0\" class=\"data row1 col0\" >1.248359</td>\n",
       "      <td id=\"T_2529b_row1_col1\" class=\"data row1 col1\" >1.185471</td>\n",
       "      <td id=\"T_2529b_row1_col2\" class=\"data row1 col2\" >1.715857</td>\n",
       "      <td id=\"T_2529b_row1_col3\" class=\"data row1 col3\" >0.988982</td>\n",
       "      <td id=\"T_2529b_row1_col4\" class=\"data row1 col4\" >1.176134</td>\n",
       "      <td id=\"T_2529b_row1_col5\" class=\"data row1 col5\" >1.674834</td>\n",
       "      <td id=\"T_2529b_row1_col6\" class=\"data row1 col6\" >1.027244</td>\n",
       "      <td id=\"T_2529b_row1_col7\" class=\"data row1 col7\" >1.202526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row2\" class=\"row_heading level0 row2\" >BA</th>\n",
       "      <td id=\"T_2529b_row2_col0\" class=\"data row2 col0\" >0.829226</td>\n",
       "      <td id=\"T_2529b_row2_col1\" class=\"data row2 col1\" >1.493071</td>\n",
       "      <td id=\"T_2529b_row2_col2\" class=\"data row2 col2\" >1.514637</td>\n",
       "      <td id=\"T_2529b_row2_col3\" class=\"data row2 col3\" >1.062981</td>\n",
       "      <td id=\"T_2529b_row2_col4\" class=\"data row2 col4\" >1.566135</td>\n",
       "      <td id=\"T_2529b_row2_col5\" class=\"data row2 col5\" >2.246748</td>\n",
       "      <td id=\"T_2529b_row2_col6\" class=\"data row2 col6\" >1.501774</td>\n",
       "      <td id=\"T_2529b_row2_col7\" class=\"data row2 col7\" >1.806060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row3\" class=\"row_heading level0 row3\" >CAT</th>\n",
       "      <td id=\"T_2529b_row3_col0\" class=\"data row3 col0\" >1.152445</td>\n",
       "      <td id=\"T_2529b_row3_col1\" class=\"data row3 col1\" >0.781887</td>\n",
       "      <td id=\"T_2529b_row3_col2\" class=\"data row3 col2\" >0.805841</td>\n",
       "      <td id=\"T_2529b_row3_col3\" class=\"data row3 col3\" >0.727624</td>\n",
       "      <td id=\"T_2529b_row3_col4\" class=\"data row3 col4\" >0.902212</td>\n",
       "      <td id=\"T_2529b_row3_col5\" class=\"data row3 col5\" >1.126989</td>\n",
       "      <td id=\"T_2529b_row3_col6\" class=\"data row3 col6\" >0.941309</td>\n",
       "      <td id=\"T_2529b_row3_col7\" class=\"data row3 col7\" >0.969601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row4\" class=\"row_heading level0 row4\" >CVX</th>\n",
       "      <td id=\"T_2529b_row4_col0\" class=\"data row4 col0\" >1.081849</td>\n",
       "      <td id=\"T_2529b_row4_col1\" class=\"data row4 col1\" >0.999687</td>\n",
       "      <td id=\"T_2529b_row4_col2\" class=\"data row4 col2\" >1.137707</td>\n",
       "      <td id=\"T_2529b_row4_col3\" class=\"data row4 col3\" >0.883496</td>\n",
       "      <td id=\"T_2529b_row4_col4\" class=\"data row4 col4\" >1.027295</td>\n",
       "      <td id=\"T_2529b_row4_col5\" class=\"data row4 col5\" >1.159879</td>\n",
       "      <td id=\"T_2529b_row4_col6\" class=\"data row4 col6\" >1.053798</td>\n",
       "      <td id=\"T_2529b_row4_col7\" class=\"data row4 col7\" >1.106623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row5\" class=\"row_heading level0 row5\" >GOOGL</th>\n",
       "      <td id=\"T_2529b_row5_col0\" class=\"data row5 col0\" >1.398305</td>\n",
       "      <td id=\"T_2529b_row5_col1\" class=\"data row5 col1\" >1.061492</td>\n",
       "      <td id=\"T_2529b_row5_col2\" class=\"data row5 col2\" >1.208705</td>\n",
       "      <td id=\"T_2529b_row5_col3\" class=\"data row5 col3\" >0.899416</td>\n",
       "      <td id=\"T_2529b_row5_col4\" class=\"data row5 col4\" >1.582171</td>\n",
       "      <td id=\"T_2529b_row5_col5\" class=\"data row5 col5\" >0.756006</td>\n",
       "      <td id=\"T_2529b_row5_col6\" class=\"data row5 col6\" >1.251464</td>\n",
       "      <td id=\"T_2529b_row5_col7\" class=\"data row5 col7\" >1.682453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row6\" class=\"row_heading level0 row6\" >GS</th>\n",
       "      <td id=\"T_2529b_row6_col0\" class=\"data row6 col0\" >1.602419</td>\n",
       "      <td id=\"T_2529b_row6_col1\" class=\"data row6 col1\" >0.879212</td>\n",
       "      <td id=\"T_2529b_row6_col2\" class=\"data row6 col2\" >0.898384</td>\n",
       "      <td id=\"T_2529b_row6_col3\" class=\"data row6 col3\" >0.792364</td>\n",
       "      <td id=\"T_2529b_row6_col4\" class=\"data row6 col4\" >1.134158</td>\n",
       "      <td id=\"T_2529b_row6_col5\" class=\"data row6 col5\" >0.759252</td>\n",
       "      <td id=\"T_2529b_row6_col6\" class=\"data row6 col6\" >1.133356</td>\n",
       "      <td id=\"T_2529b_row6_col7\" class=\"data row6 col7\" >1.097155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row7\" class=\"row_heading level0 row7\" >JNJ</th>\n",
       "      <td id=\"T_2529b_row7_col0\" class=\"data row7 col0\" >0.937535</td>\n",
       "      <td id=\"T_2529b_row7_col1\" class=\"data row7 col1\" >0.921409</td>\n",
       "      <td id=\"T_2529b_row7_col2\" class=\"data row7 col2\" >0.704953</td>\n",
       "      <td id=\"T_2529b_row7_col3\" class=\"data row7 col3\" >0.948827</td>\n",
       "      <td id=\"T_2529b_row7_col4\" class=\"data row7 col4\" >0.914624</td>\n",
       "      <td id=\"T_2529b_row7_col5\" class=\"data row7 col5\" >1.088954</td>\n",
       "      <td id=\"T_2529b_row7_col6\" class=\"data row7 col6\" >0.972660</td>\n",
       "      <td id=\"T_2529b_row7_col7\" class=\"data row7 col7\" >0.947512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row8\" class=\"row_heading level0 row8\" >JPM</th>\n",
       "      <td id=\"T_2529b_row8_col0\" class=\"data row8 col0\" >1.397843</td>\n",
       "      <td id=\"T_2529b_row8_col1\" class=\"data row8 col1\" >0.861837</td>\n",
       "      <td id=\"T_2529b_row8_col2\" class=\"data row8 col2\" >0.815238</td>\n",
       "      <td id=\"T_2529b_row8_col3\" class=\"data row8 col3\" >0.929981</td>\n",
       "      <td id=\"T_2529b_row8_col4\" class=\"data row8 col4\" >0.967421</td>\n",
       "      <td id=\"T_2529b_row8_col5\" class=\"data row8 col5\" >0.955670</td>\n",
       "      <td id=\"T_2529b_row8_col6\" class=\"data row8 col6\" >0.886310</td>\n",
       "      <td id=\"T_2529b_row8_col7\" class=\"data row8 col7\" >1.029995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row9\" class=\"row_heading level0 row9\" >KO</th>\n",
       "      <td id=\"T_2529b_row9_col0\" class=\"data row9 col0\" >1.068831</td>\n",
       "      <td id=\"T_2529b_row9_col1\" class=\"data row9 col1\" >0.913828</td>\n",
       "      <td id=\"T_2529b_row9_col2\" class=\"data row9 col2\" >0.874081</td>\n",
       "      <td id=\"T_2529b_row9_col3\" class=\"data row9 col3\" >1.001360</td>\n",
       "      <td id=\"T_2529b_row9_col4\" class=\"data row9 col4\" >1.141900</td>\n",
       "      <td id=\"T_2529b_row9_col5\" class=\"data row9 col5\" >1.057325</td>\n",
       "      <td id=\"T_2529b_row9_col6\" class=\"data row9 col6\" >1.102259</td>\n",
       "      <td id=\"T_2529b_row9_col7\" class=\"data row9 col7\" >1.082110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row10\" class=\"row_heading level0 row10\" >MCD</th>\n",
       "      <td id=\"T_2529b_row10_col0\" class=\"data row10 col0\" >0.974744</td>\n",
       "      <td id=\"T_2529b_row10_col1\" class=\"data row10 col1\" >1.260876</td>\n",
       "      <td id=\"T_2529b_row10_col2\" class=\"data row10 col2\" >1.122143</td>\n",
       "      <td id=\"T_2529b_row10_col3\" class=\"data row10 col3\" >1.280713</td>\n",
       "      <td id=\"T_2529b_row10_col4\" class=\"data row10 col4\" >0.894183</td>\n",
       "      <td id=\"T_2529b_row10_col5\" class=\"data row10 col5\" >1.125647</td>\n",
       "      <td id=\"T_2529b_row10_col6\" class=\"data row10 col6\" >0.882281</td>\n",
       "      <td id=\"T_2529b_row10_col7\" class=\"data row10 col7\" >0.900293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row11\" class=\"row_heading level0 row11\" >MSFT</th>\n",
       "      <td id=\"T_2529b_row11_col0\" class=\"data row11 col0\" >1.032215</td>\n",
       "      <td id=\"T_2529b_row11_col1\" class=\"data row11 col1\" >0.804824</td>\n",
       "      <td id=\"T_2529b_row11_col2\" class=\"data row11 col2\" >0.881795</td>\n",
       "      <td id=\"T_2529b_row11_col3\" class=\"data row11 col3\" >1.052210</td>\n",
       "      <td id=\"T_2529b_row11_col4\" class=\"data row11 col4\" >0.987957</td>\n",
       "      <td id=\"T_2529b_row11_col5\" class=\"data row11 col5\" >1.015916</td>\n",
       "      <td id=\"T_2529b_row11_col6\" class=\"data row11 col6\" >0.910502</td>\n",
       "      <td id=\"T_2529b_row11_col7\" class=\"data row11 col7\" >0.947429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row12\" class=\"row_heading level0 row12\" >NKE</th>\n",
       "      <td id=\"T_2529b_row12_col0\" class=\"data row12 col0\" >0.695947</td>\n",
       "      <td id=\"T_2529b_row12_col1\" class=\"data row12 col1\" >0.608828</td>\n",
       "      <td id=\"T_2529b_row12_col2\" class=\"data row12 col2\" >0.648496</td>\n",
       "      <td id=\"T_2529b_row12_col3\" class=\"data row12 col3\" >0.623045</td>\n",
       "      <td id=\"T_2529b_row12_col4\" class=\"data row12 col4\" >0.911559</td>\n",
       "      <td id=\"T_2529b_row12_col5\" class=\"data row12 col5\" >1.240833</td>\n",
       "      <td id=\"T_2529b_row12_col6\" class=\"data row12 col6\" >1.607401</td>\n",
       "      <td id=\"T_2529b_row12_col7\" class=\"data row12 col7\" >0.893136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row13\" class=\"row_heading level0 row13\" >NVDA</th>\n",
       "      <td id=\"T_2529b_row13_col0\" class=\"data row13 col0\" >1.688845</td>\n",
       "      <td id=\"T_2529b_row13_col1\" class=\"data row13 col1\" >2.076737</td>\n",
       "      <td id=\"T_2529b_row13_col2\" class=\"data row13 col2\" >0.497619</td>\n",
       "      <td id=\"T_2529b_row13_col3\" class=\"data row13 col3\" >1.400347</td>\n",
       "      <td id=\"T_2529b_row13_col4\" class=\"data row13 col4\" >1.124511</td>\n",
       "      <td id=\"T_2529b_row13_col5\" class=\"data row13 col5\" >1.138686</td>\n",
       "      <td id=\"T_2529b_row13_col6\" class=\"data row13 col6\" >1.091795</td>\n",
       "      <td id=\"T_2529b_row13_col7\" class=\"data row13 col7\" >1.156391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row14\" class=\"row_heading level0 row14\" >PFE</th>\n",
       "      <td id=\"T_2529b_row14_col0\" class=\"data row14 col0\" >1.042641</td>\n",
       "      <td id=\"T_2529b_row14_col1\" class=\"data row14 col1\" >0.716187</td>\n",
       "      <td id=\"T_2529b_row14_col2\" class=\"data row14 col2\" >0.894264</td>\n",
       "      <td id=\"T_2529b_row14_col3\" class=\"data row14 col3\" >0.672112</td>\n",
       "      <td id=\"T_2529b_row14_col4\" class=\"data row14 col4\" >0.984625</td>\n",
       "      <td id=\"T_2529b_row14_col5\" class=\"data row14 col5\" >0.753015</td>\n",
       "      <td id=\"T_2529b_row14_col6\" class=\"data row14 col6\" >1.005529</td>\n",
       "      <td id=\"T_2529b_row14_col7\" class=\"data row14 col7\" >0.994814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row15\" class=\"row_heading level0 row15\" >SOFI</th>\n",
       "      <td id=\"T_2529b_row15_col0\" class=\"data row15 col0\" >1.815145</td>\n",
       "      <td id=\"T_2529b_row15_col1\" class=\"data row15 col1\" >1.269418</td>\n",
       "      <td id=\"T_2529b_row15_col2\" class=\"data row15 col2\" >0.659616</td>\n",
       "      <td id=\"T_2529b_row15_col3\" class=\"data row15 col3\" >1.097174</td>\n",
       "      <td id=\"T_2529b_row15_col4\" class=\"data row15 col4\" >0.910422</td>\n",
       "      <td id=\"T_2529b_row15_col5\" class=\"data row15 col5\" >0.622540</td>\n",
       "      <td id=\"T_2529b_row15_col6\" class=\"data row15 col6\" >1.081450</td>\n",
       "      <td id=\"T_2529b_row15_col7\" class=\"data row15 col7\" >0.900898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row16\" class=\"row_heading level0 row16\" >TSLA</th>\n",
       "      <td id=\"T_2529b_row16_col0\" class=\"data row16 col0\" >2.049832</td>\n",
       "      <td id=\"T_2529b_row16_col1\" class=\"data row16 col1\" >0.350023</td>\n",
       "      <td id=\"T_2529b_row16_col2\" class=\"data row16 col2\" >0.511562</td>\n",
       "      <td id=\"T_2529b_row16_col3\" class=\"data row16 col3\" >0.405429</td>\n",
       "      <td id=\"T_2529b_row16_col4\" class=\"data row16 col4\" >0.273532</td>\n",
       "      <td id=\"T_2529b_row16_col5\" class=\"data row16 col5\" >0.473348</td>\n",
       "      <td id=\"T_2529b_row16_col6\" class=\"data row16 col6\" >0.367686</td>\n",
       "      <td id=\"T_2529b_row16_col7\" class=\"data row16 col7\" >0.298047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row17\" class=\"row_heading level0 row17\" >UNH</th>\n",
       "      <td id=\"T_2529b_row17_col0\" class=\"data row17 col0\" >1.050616</td>\n",
       "      <td id=\"T_2529b_row17_col1\" class=\"data row17 col1\" >0.825169</td>\n",
       "      <td id=\"T_2529b_row17_col2\" class=\"data row17 col2\" >1.033698</td>\n",
       "      <td id=\"T_2529b_row17_col3\" class=\"data row17 col3\" >0.790846</td>\n",
       "      <td id=\"T_2529b_row17_col4\" class=\"data row17 col4\" >0.964540</td>\n",
       "      <td id=\"T_2529b_row17_col5\" class=\"data row17 col5\" >1.075506</td>\n",
       "      <td id=\"T_2529b_row17_col6\" class=\"data row17 col6\" >0.972657</td>\n",
       "      <td id=\"T_2529b_row17_col7\" class=\"data row17 col7\" >1.012462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row18\" class=\"row_heading level0 row18\" >WMT</th>\n",
       "      <td id=\"T_2529b_row18_col0\" class=\"data row18 col0\" >1.576426</td>\n",
       "      <td id=\"T_2529b_row18_col1\" class=\"data row18 col1\" >1.315369</td>\n",
       "      <td id=\"T_2529b_row18_col2\" class=\"data row18 col2\" >0.794413</td>\n",
       "      <td id=\"T_2529b_row18_col3\" class=\"data row18 col3\" >1.140859</td>\n",
       "      <td id=\"T_2529b_row18_col4\" class=\"data row18 col4\" >1.129073</td>\n",
       "      <td id=\"T_2529b_row18_col5\" class=\"data row18 col5\" >0.973878</td>\n",
       "      <td id=\"T_2529b_row18_col6\" class=\"data row18 col6\" >1.149815</td>\n",
       "      <td id=\"T_2529b_row18_col7\" class=\"data row18 col7\" >1.152748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2529b_level0_row19\" class=\"row_heading level0 row19\" >XOM</th>\n",
       "      <td id=\"T_2529b_row19_col0\" class=\"data row19 col0\" >1.091248</td>\n",
       "      <td id=\"T_2529b_row19_col1\" class=\"data row19 col1\" >0.875350</td>\n",
       "      <td id=\"T_2529b_row19_col2\" class=\"data row19 col2\" >1.276171</td>\n",
       "      <td id=\"T_2529b_row19_col3\" class=\"data row19 col3\" >0.967064</td>\n",
       "      <td id=\"T_2529b_row19_col4\" class=\"data row19 col4\" >0.899198</td>\n",
       "      <td id=\"T_2529b_row19_col5\" class=\"data row19 col5\" >0.928740</td>\n",
       "      <td id=\"T_2529b_row19_col6\" class=\"data row19 col6\" >0.881584</td>\n",
       "      <td id=\"T_2529b_row19_col7\" class=\"data row19 col7\" >0.890231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2437e3cc2b0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate them side by side\n",
    "merged_df = pd.concat([styled_df_roll2, styled_df_roll3], axis=1)\n",
    "\n",
    "cols_to_drop = ['Benchmark_Roll_3']  # replace with your actual column names\n",
    "merged_df = merged_df.drop(columns=cols_to_drop)\n",
    "\n",
    "mask = merged_df.eq(merged_df.max(axis=1), axis=0)\n",
    "\n",
    "# Drop columns that are never the max in any row\n",
    "cols_to_keep = mask.any(axis=0)\n",
    "merged_df = merged_df.loc[:, cols_to_keep]\n",
    "\n",
    "\n",
    "merged_df = merged_df.style.apply(highlight_max_row, axis=1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7512e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3f2e6_row0_col0, #T_3f2e6_row1_col2, #T_3f2e6_row2_col5, #T_3f2e6_row3_col12, #T_3f2e6_row4_col5, #T_3f2e6_row5_col7, #T_3f2e6_row6_col0, #T_3f2e6_row7_col14, #T_3f2e6_row8_col0, #T_3f2e6_row8_col9, #T_3f2e6_row8_col10, #T_3f2e6_row8_col11, #T_3f2e6_row8_col13, #T_3f2e6_row8_col16, #T_3f2e6_row9_col4, #T_3f2e6_row10_col3, #T_3f2e6_row11_col8, #T_3f2e6_row12_col6, #T_3f2e6_row13_col1, #T_3f2e6_row14_col9, #T_3f2e6_row15_col0, #T_3f2e6_row16_col0, #T_3f2e6_row17_col11, #T_3f2e6_row18_col0, #T_3f2e6_row18_col9, #T_3f2e6_row18_col10, #T_3f2e6_row18_col11, #T_3f2e6_row18_col13, #T_3f2e6_row18_col15, #T_3f2e6_row18_col16, #T_3f2e6_row19_col2 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3f2e6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3f2e6_level0_col0\" class=\"col_heading level0 col0\" >Benchmark_Roll_2</th>\n",
       "      <th id=\"T_3f2e6_level0_col1\" class=\"col_heading level0 col1\" >LinReg_Roll_2</th>\n",
       "      <th id=\"T_3f2e6_level0_col2\" class=\"col_heading level0 col2\" >DecisionTree_Roll_2</th>\n",
       "      <th id=\"T_3f2e6_level0_col3\" class=\"col_heading level0 col3\" >LinReg_Roll_3</th>\n",
       "      <th id=\"T_3f2e6_level0_col4\" class=\"col_heading level0 col4\" >Logistic_Roll_3</th>\n",
       "      <th id=\"T_3f2e6_level0_col5\" class=\"col_heading level0 col5\" >DecisionTree_Roll_3</th>\n",
       "      <th id=\"T_3f2e6_level0_col6\" class=\"col_heading level0 col6\" >DNN_Roll_3</th>\n",
       "      <th id=\"T_3f2e6_level0_col7\" class=\"col_heading level0 col7\" >SVC_Roll_3</th>\n",
       "      <th id=\"T_3f2e6_level0_col8\" class=\"col_heading level0 col8\" >LinReg_Exp_2</th>\n",
       "      <th id=\"T_3f2e6_level0_col9\" class=\"col_heading level0 col9\" >Logistic_Exp_2</th>\n",
       "      <th id=\"T_3f2e6_level0_col10\" class=\"col_heading level0 col10\" >DNN_Exp_2</th>\n",
       "      <th id=\"T_3f2e6_level0_col11\" class=\"col_heading level0 col11\" >SVC_Exp_2</th>\n",
       "      <th id=\"T_3f2e6_level0_col12\" class=\"col_heading level0 col12\" >LinReg_Exp_3</th>\n",
       "      <th id=\"T_3f2e6_level0_col13\" class=\"col_heading level0 col13\" >Logistic_Exp_3</th>\n",
       "      <th id=\"T_3f2e6_level0_col14\" class=\"col_heading level0 col14\" >DecisionTree_Exp_3</th>\n",
       "      <th id=\"T_3f2e6_level0_col15\" class=\"col_heading level0 col15\" >DNN_Exp_3</th>\n",
       "      <th id=\"T_3f2e6_level0_col16\" class=\"col_heading level0 col16\" >SVC_Exp_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row0\" class=\"row_heading level0 row0\" >AAPL</th>\n",
       "      <td id=\"T_3f2e6_row0_col0\" class=\"data row0 col0\" >1.267419</td>\n",
       "      <td id=\"T_3f2e6_row0_col1\" class=\"data row0 col1\" >0.754734</td>\n",
       "      <td id=\"T_3f2e6_row0_col2\" class=\"data row0 col2\" >0.954708</td>\n",
       "      <td id=\"T_3f2e6_row0_col3\" class=\"data row0 col3\" >0.870786</td>\n",
       "      <td id=\"T_3f2e6_row0_col4\" class=\"data row0 col4\" >1.117342</td>\n",
       "      <td id=\"T_3f2e6_row0_col5\" class=\"data row0 col5\" >0.710308</td>\n",
       "      <td id=\"T_3f2e6_row0_col6\" class=\"data row0 col6\" >1.054113</td>\n",
       "      <td id=\"T_3f2e6_row0_col7\" class=\"data row0 col7\" >1.117342</td>\n",
       "      <td id=\"T_3f2e6_row0_col8\" class=\"data row0 col8\" >0.773309</td>\n",
       "      <td id=\"T_3f2e6_row0_col9\" class=\"data row0 col9\" >1.096886</td>\n",
       "      <td id=\"T_3f2e6_row0_col10\" class=\"data row0 col10\" >1.108475</td>\n",
       "      <td id=\"T_3f2e6_row0_col11\" class=\"data row0 col11\" >1.096886</td>\n",
       "      <td id=\"T_3f2e6_row0_col12\" class=\"data row0 col12\" >0.747006</td>\n",
       "      <td id=\"T_3f2e6_row0_col13\" class=\"data row0 col13\" >1.117292</td>\n",
       "      <td id=\"T_3f2e6_row0_col14\" class=\"data row0 col14\" >0.867616</td>\n",
       "      <td id=\"T_3f2e6_row0_col15\" class=\"data row0 col15\" >1.108475</td>\n",
       "      <td id=\"T_3f2e6_row0_col16\" class=\"data row0 col16\" >1.117292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row1\" class=\"row_heading level0 row1\" >AMZN</th>\n",
       "      <td id=\"T_3f2e6_row1_col0\" class=\"data row1 col0\" >1.248359</td>\n",
       "      <td id=\"T_3f2e6_row1_col1\" class=\"data row1 col1\" >1.185471</td>\n",
       "      <td id=\"T_3f2e6_row1_col2\" class=\"data row1 col2\" >1.715857</td>\n",
       "      <td id=\"T_3f2e6_row1_col3\" class=\"data row1 col3\" >0.988982</td>\n",
       "      <td id=\"T_3f2e6_row1_col4\" class=\"data row1 col4\" >1.176134</td>\n",
       "      <td id=\"T_3f2e6_row1_col5\" class=\"data row1 col5\" >1.674834</td>\n",
       "      <td id=\"T_3f2e6_row1_col6\" class=\"data row1 col6\" >1.027244</td>\n",
       "      <td id=\"T_3f2e6_row1_col7\" class=\"data row1 col7\" >1.202526</td>\n",
       "      <td id=\"T_3f2e6_row1_col8\" class=\"data row1 col8\" >1.308805</td>\n",
       "      <td id=\"T_3f2e6_row1_col9\" class=\"data row1 col9\" >1.223966</td>\n",
       "      <td id=\"T_3f2e6_row1_col10\" class=\"data row1 col10\" >1.298234</td>\n",
       "      <td id=\"T_3f2e6_row1_col11\" class=\"data row1 col11\" >1.211303</td>\n",
       "      <td id=\"T_3f2e6_row1_col12\" class=\"data row1 col12\" >1.181126</td>\n",
       "      <td id=\"T_3f2e6_row1_col13\" class=\"data row1 col13\" >1.272808</td>\n",
       "      <td id=\"T_3f2e6_row1_col14\" class=\"data row1 col14\" >1.344734</td>\n",
       "      <td id=\"T_3f2e6_row1_col15\" class=\"data row1 col15\" >1.192535</td>\n",
       "      <td id=\"T_3f2e6_row1_col16\" class=\"data row1 col16\" >1.280192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row2\" class=\"row_heading level0 row2\" >BA</th>\n",
       "      <td id=\"T_3f2e6_row2_col0\" class=\"data row2 col0\" >0.829226</td>\n",
       "      <td id=\"T_3f2e6_row2_col1\" class=\"data row2 col1\" >1.493071</td>\n",
       "      <td id=\"T_3f2e6_row2_col2\" class=\"data row2 col2\" >1.514637</td>\n",
       "      <td id=\"T_3f2e6_row2_col3\" class=\"data row2 col3\" >1.062981</td>\n",
       "      <td id=\"T_3f2e6_row2_col4\" class=\"data row2 col4\" >1.566135</td>\n",
       "      <td id=\"T_3f2e6_row2_col5\" class=\"data row2 col5\" >2.246748</td>\n",
       "      <td id=\"T_3f2e6_row2_col6\" class=\"data row2 col6\" >1.501774</td>\n",
       "      <td id=\"T_3f2e6_row2_col7\" class=\"data row2 col7\" >1.806060</td>\n",
       "      <td id=\"T_3f2e6_row2_col8\" class=\"data row2 col8\" >1.028124</td>\n",
       "      <td id=\"T_3f2e6_row2_col9\" class=\"data row2 col9\" >1.205943</td>\n",
       "      <td id=\"T_3f2e6_row2_col10\" class=\"data row2 col10\" >1.205943</td>\n",
       "      <td id=\"T_3f2e6_row2_col11\" class=\"data row2 col11\" >1.205943</td>\n",
       "      <td id=\"T_3f2e6_row2_col12\" class=\"data row2 col12\" >1.405644</td>\n",
       "      <td id=\"T_3f2e6_row2_col13\" class=\"data row2 col13\" >1.205943</td>\n",
       "      <td id=\"T_3f2e6_row2_col14\" class=\"data row2 col14\" >1.170797</td>\n",
       "      <td id=\"T_3f2e6_row2_col15\" class=\"data row2 col15\" >1.205943</td>\n",
       "      <td id=\"T_3f2e6_row2_col16\" class=\"data row2 col16\" >1.205943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row3\" class=\"row_heading level0 row3\" >CAT</th>\n",
       "      <td id=\"T_3f2e6_row3_col0\" class=\"data row3 col0\" >1.152445</td>\n",
       "      <td id=\"T_3f2e6_row3_col1\" class=\"data row3 col1\" >0.781887</td>\n",
       "      <td id=\"T_3f2e6_row3_col2\" class=\"data row3 col2\" >0.805841</td>\n",
       "      <td id=\"T_3f2e6_row3_col3\" class=\"data row3 col3\" >0.727624</td>\n",
       "      <td id=\"T_3f2e6_row3_col4\" class=\"data row3 col4\" >0.902212</td>\n",
       "      <td id=\"T_3f2e6_row3_col5\" class=\"data row3 col5\" >1.126989</td>\n",
       "      <td id=\"T_3f2e6_row3_col6\" class=\"data row3 col6\" >0.941309</td>\n",
       "      <td id=\"T_3f2e6_row3_col7\" class=\"data row3 col7\" >0.969601</td>\n",
       "      <td id=\"T_3f2e6_row3_col8\" class=\"data row3 col8\" >0.891585</td>\n",
       "      <td id=\"T_3f2e6_row3_col9\" class=\"data row3 col9\" >1.152445</td>\n",
       "      <td id=\"T_3f2e6_row3_col10\" class=\"data row3 col10\" >1.169168</td>\n",
       "      <td id=\"T_3f2e6_row3_col11\" class=\"data row3 col11\" >1.152445</td>\n",
       "      <td id=\"T_3f2e6_row3_col12\" class=\"data row3 col12\" >1.750360</td>\n",
       "      <td id=\"T_3f2e6_row3_col13\" class=\"data row3 col13\" >1.152445</td>\n",
       "      <td id=\"T_3f2e6_row3_col14\" class=\"data row3 col14\" >1.028154</td>\n",
       "      <td id=\"T_3f2e6_row3_col15\" class=\"data row3 col15\" >1.173240</td>\n",
       "      <td id=\"T_3f2e6_row3_col16\" class=\"data row3 col16\" >1.152445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row4\" class=\"row_heading level0 row4\" >CVX</th>\n",
       "      <td id=\"T_3f2e6_row4_col0\" class=\"data row4 col0\" >1.081849</td>\n",
       "      <td id=\"T_3f2e6_row4_col1\" class=\"data row4 col1\" >0.999687</td>\n",
       "      <td id=\"T_3f2e6_row4_col2\" class=\"data row4 col2\" >1.137707</td>\n",
       "      <td id=\"T_3f2e6_row4_col3\" class=\"data row4 col3\" >0.883496</td>\n",
       "      <td id=\"T_3f2e6_row4_col4\" class=\"data row4 col4\" >1.027295</td>\n",
       "      <td id=\"T_3f2e6_row4_col5\" class=\"data row4 col5\" >1.159879</td>\n",
       "      <td id=\"T_3f2e6_row4_col6\" class=\"data row4 col6\" >1.053798</td>\n",
       "      <td id=\"T_3f2e6_row4_col7\" class=\"data row4 col7\" >1.106623</td>\n",
       "      <td id=\"T_3f2e6_row4_col8\" class=\"data row4 col8\" >1.002691</td>\n",
       "      <td id=\"T_3f2e6_row4_col9\" class=\"data row4 col9\" >1.081849</td>\n",
       "      <td id=\"T_3f2e6_row4_col10\" class=\"data row4 col10\" >1.081849</td>\n",
       "      <td id=\"T_3f2e6_row4_col11\" class=\"data row4 col11\" >1.081849</td>\n",
       "      <td id=\"T_3f2e6_row4_col12\" class=\"data row4 col12\" >0.854204</td>\n",
       "      <td id=\"T_3f2e6_row4_col13\" class=\"data row4 col13\" >1.081849</td>\n",
       "      <td id=\"T_3f2e6_row4_col14\" class=\"data row4 col14\" >0.919006</td>\n",
       "      <td id=\"T_3f2e6_row4_col15\" class=\"data row4 col15\" >1.081849</td>\n",
       "      <td id=\"T_3f2e6_row4_col16\" class=\"data row4 col16\" >1.081849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row5\" class=\"row_heading level0 row5\" >GOOGL</th>\n",
       "      <td id=\"T_3f2e6_row5_col0\" class=\"data row5 col0\" >1.398305</td>\n",
       "      <td id=\"T_3f2e6_row5_col1\" class=\"data row5 col1\" >1.061492</td>\n",
       "      <td id=\"T_3f2e6_row5_col2\" class=\"data row5 col2\" >1.208705</td>\n",
       "      <td id=\"T_3f2e6_row5_col3\" class=\"data row5 col3\" >0.899416</td>\n",
       "      <td id=\"T_3f2e6_row5_col4\" class=\"data row5 col4\" >1.582171</td>\n",
       "      <td id=\"T_3f2e6_row5_col5\" class=\"data row5 col5\" >0.756006</td>\n",
       "      <td id=\"T_3f2e6_row5_col6\" class=\"data row5 col6\" >1.251464</td>\n",
       "      <td id=\"T_3f2e6_row5_col7\" class=\"data row5 col7\" >1.682453</td>\n",
       "      <td id=\"T_3f2e6_row5_col8\" class=\"data row5 col8\" >1.151027</td>\n",
       "      <td id=\"T_3f2e6_row5_col9\" class=\"data row5 col9\" >1.398305</td>\n",
       "      <td id=\"T_3f2e6_row5_col10\" class=\"data row5 col10\" >1.398305</td>\n",
       "      <td id=\"T_3f2e6_row5_col11\" class=\"data row5 col11\" >1.398305</td>\n",
       "      <td id=\"T_3f2e6_row5_col12\" class=\"data row5 col12\" >1.056617</td>\n",
       "      <td id=\"T_3f2e6_row5_col13\" class=\"data row5 col13\" >1.398305</td>\n",
       "      <td id=\"T_3f2e6_row5_col14\" class=\"data row5 col14\" >1.034177</td>\n",
       "      <td id=\"T_3f2e6_row5_col15\" class=\"data row5 col15\" >1.398305</td>\n",
       "      <td id=\"T_3f2e6_row5_col16\" class=\"data row5 col16\" >1.398305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row6\" class=\"row_heading level0 row6\" >GS</th>\n",
       "      <td id=\"T_3f2e6_row6_col0\" class=\"data row6 col0\" >1.602419</td>\n",
       "      <td id=\"T_3f2e6_row6_col1\" class=\"data row6 col1\" >0.879212</td>\n",
       "      <td id=\"T_3f2e6_row6_col2\" class=\"data row6 col2\" >0.898384</td>\n",
       "      <td id=\"T_3f2e6_row6_col3\" class=\"data row6 col3\" >0.792364</td>\n",
       "      <td id=\"T_3f2e6_row6_col4\" class=\"data row6 col4\" >1.134158</td>\n",
       "      <td id=\"T_3f2e6_row6_col5\" class=\"data row6 col5\" >0.759252</td>\n",
       "      <td id=\"T_3f2e6_row6_col6\" class=\"data row6 col6\" >1.133356</td>\n",
       "      <td id=\"T_3f2e6_row6_col7\" class=\"data row6 col7\" >1.097155</td>\n",
       "      <td id=\"T_3f2e6_row6_col8\" class=\"data row6 col8\" >1.284154</td>\n",
       "      <td id=\"T_3f2e6_row6_col9\" class=\"data row6 col9\" >1.233984</td>\n",
       "      <td id=\"T_3f2e6_row6_col10\" class=\"data row6 col10\" >1.165450</td>\n",
       "      <td id=\"T_3f2e6_row6_col11\" class=\"data row6 col11\" >1.243185</td>\n",
       "      <td id=\"T_3f2e6_row6_col12\" class=\"data row6 col12\" >1.104987</td>\n",
       "      <td id=\"T_3f2e6_row6_col13\" class=\"data row6 col13\" >1.231658</td>\n",
       "      <td id=\"T_3f2e6_row6_col14\" class=\"data row6 col14\" >1.420511</td>\n",
       "      <td id=\"T_3f2e6_row6_col15\" class=\"data row6 col15\" >1.260821</td>\n",
       "      <td id=\"T_3f2e6_row6_col16\" class=\"data row6 col16\" >1.231658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row7\" class=\"row_heading level0 row7\" >JNJ</th>\n",
       "      <td id=\"T_3f2e6_row7_col0\" class=\"data row7 col0\" >0.937535</td>\n",
       "      <td id=\"T_3f2e6_row7_col1\" class=\"data row7 col1\" >0.921409</td>\n",
       "      <td id=\"T_3f2e6_row7_col2\" class=\"data row7 col2\" >0.704953</td>\n",
       "      <td id=\"T_3f2e6_row7_col3\" class=\"data row7 col3\" >0.948827</td>\n",
       "      <td id=\"T_3f2e6_row7_col4\" class=\"data row7 col4\" >0.914624</td>\n",
       "      <td id=\"T_3f2e6_row7_col5\" class=\"data row7 col5\" >1.088954</td>\n",
       "      <td id=\"T_3f2e6_row7_col6\" class=\"data row7 col6\" >0.972660</td>\n",
       "      <td id=\"T_3f2e6_row7_col7\" class=\"data row7 col7\" >0.947512</td>\n",
       "      <td id=\"T_3f2e6_row7_col8\" class=\"data row7 col8\" >0.885542</td>\n",
       "      <td id=\"T_3f2e6_row7_col9\" class=\"data row7 col9\" >0.957063</td>\n",
       "      <td id=\"T_3f2e6_row7_col10\" class=\"data row7 col10\" >1.057288</td>\n",
       "      <td id=\"T_3f2e6_row7_col11\" class=\"data row7 col11\" >0.952611</td>\n",
       "      <td id=\"T_3f2e6_row7_col12\" class=\"data row7 col12\" >0.797954</td>\n",
       "      <td id=\"T_3f2e6_row7_col13\" class=\"data row7 col13\" >0.974571</td>\n",
       "      <td id=\"T_3f2e6_row7_col14\" class=\"data row7 col14\" >1.100090</td>\n",
       "      <td id=\"T_3f2e6_row7_col15\" class=\"data row7 col15\" >0.982131</td>\n",
       "      <td id=\"T_3f2e6_row7_col16\" class=\"data row7 col16\" >0.975678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row8\" class=\"row_heading level0 row8\" >JPM</th>\n",
       "      <td id=\"T_3f2e6_row8_col0\" class=\"data row8 col0\" >1.397843</td>\n",
       "      <td id=\"T_3f2e6_row8_col1\" class=\"data row8 col1\" >0.861837</td>\n",
       "      <td id=\"T_3f2e6_row8_col2\" class=\"data row8 col2\" >0.815238</td>\n",
       "      <td id=\"T_3f2e6_row8_col3\" class=\"data row8 col3\" >0.929981</td>\n",
       "      <td id=\"T_3f2e6_row8_col4\" class=\"data row8 col4\" >0.967421</td>\n",
       "      <td id=\"T_3f2e6_row8_col5\" class=\"data row8 col5\" >0.955670</td>\n",
       "      <td id=\"T_3f2e6_row8_col6\" class=\"data row8 col6\" >0.886310</td>\n",
       "      <td id=\"T_3f2e6_row8_col7\" class=\"data row8 col7\" >1.029995</td>\n",
       "      <td id=\"T_3f2e6_row8_col8\" class=\"data row8 col8\" >1.366353</td>\n",
       "      <td id=\"T_3f2e6_row8_col9\" class=\"data row8 col9\" >1.397843</td>\n",
       "      <td id=\"T_3f2e6_row8_col10\" class=\"data row8 col10\" >1.397843</td>\n",
       "      <td id=\"T_3f2e6_row8_col11\" class=\"data row8 col11\" >1.397843</td>\n",
       "      <td id=\"T_3f2e6_row8_col12\" class=\"data row8 col12\" >0.929259</td>\n",
       "      <td id=\"T_3f2e6_row8_col13\" class=\"data row8 col13\" >1.397843</td>\n",
       "      <td id=\"T_3f2e6_row8_col14\" class=\"data row8 col14\" >1.178907</td>\n",
       "      <td id=\"T_3f2e6_row8_col15\" class=\"data row8 col15\" >1.394694</td>\n",
       "      <td id=\"T_3f2e6_row8_col16\" class=\"data row8 col16\" >1.397843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row9\" class=\"row_heading level0 row9\" >KO</th>\n",
       "      <td id=\"T_3f2e6_row9_col0\" class=\"data row9 col0\" >1.068831</td>\n",
       "      <td id=\"T_3f2e6_row9_col1\" class=\"data row9 col1\" >0.913828</td>\n",
       "      <td id=\"T_3f2e6_row9_col2\" class=\"data row9 col2\" >0.874081</td>\n",
       "      <td id=\"T_3f2e6_row9_col3\" class=\"data row9 col3\" >1.001360</td>\n",
       "      <td id=\"T_3f2e6_row9_col4\" class=\"data row9 col4\" >1.141900</td>\n",
       "      <td id=\"T_3f2e6_row9_col5\" class=\"data row9 col5\" >1.057325</td>\n",
       "      <td id=\"T_3f2e6_row9_col6\" class=\"data row9 col6\" >1.102259</td>\n",
       "      <td id=\"T_3f2e6_row9_col7\" class=\"data row9 col7\" >1.082110</td>\n",
       "      <td id=\"T_3f2e6_row9_col8\" class=\"data row9 col8\" >1.018933</td>\n",
       "      <td id=\"T_3f2e6_row9_col9\" class=\"data row9 col9\" >1.024618</td>\n",
       "      <td id=\"T_3f2e6_row9_col10\" class=\"data row9 col10\" >1.050077</td>\n",
       "      <td id=\"T_3f2e6_row9_col11\" class=\"data row9 col11\" >1.021800</td>\n",
       "      <td id=\"T_3f2e6_row9_col12\" class=\"data row9 col12\" >1.058875</td>\n",
       "      <td id=\"T_3f2e6_row9_col13\" class=\"data row9 col13\" >1.016329</td>\n",
       "      <td id=\"T_3f2e6_row9_col14\" class=\"data row9 col14\" >0.832374</td>\n",
       "      <td id=\"T_3f2e6_row9_col15\" class=\"data row9 col15\" >1.027762</td>\n",
       "      <td id=\"T_3f2e6_row9_col16\" class=\"data row9 col16\" >1.016329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row10\" class=\"row_heading level0 row10\" >MCD</th>\n",
       "      <td id=\"T_3f2e6_row10_col0\" class=\"data row10 col0\" >0.974744</td>\n",
       "      <td id=\"T_3f2e6_row10_col1\" class=\"data row10 col1\" >1.260876</td>\n",
       "      <td id=\"T_3f2e6_row10_col2\" class=\"data row10 col2\" >1.122143</td>\n",
       "      <td id=\"T_3f2e6_row10_col3\" class=\"data row10 col3\" >1.280713</td>\n",
       "      <td id=\"T_3f2e6_row10_col4\" class=\"data row10 col4\" >0.894183</td>\n",
       "      <td id=\"T_3f2e6_row10_col5\" class=\"data row10 col5\" >1.125647</td>\n",
       "      <td id=\"T_3f2e6_row10_col6\" class=\"data row10 col6\" >0.882281</td>\n",
       "      <td id=\"T_3f2e6_row10_col7\" class=\"data row10 col7\" >0.900293</td>\n",
       "      <td id=\"T_3f2e6_row10_col8\" class=\"data row10 col8\" >1.152518</td>\n",
       "      <td id=\"T_3f2e6_row10_col9\" class=\"data row10 col9\" >0.786201</td>\n",
       "      <td id=\"T_3f2e6_row10_col10\" class=\"data row10 col10\" >0.761941</td>\n",
       "      <td id=\"T_3f2e6_row10_col11\" class=\"data row10 col11\" >0.781899</td>\n",
       "      <td id=\"T_3f2e6_row10_col12\" class=\"data row10 col12\" >1.060039</td>\n",
       "      <td id=\"T_3f2e6_row10_col13\" class=\"data row10 col13\" >0.823010</td>\n",
       "      <td id=\"T_3f2e6_row10_col14\" class=\"data row10 col14\" >0.863242</td>\n",
       "      <td id=\"T_3f2e6_row10_col15\" class=\"data row10 col15\" >0.945601</td>\n",
       "      <td id=\"T_3f2e6_row10_col16\" class=\"data row10 col16\" >0.823010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row11\" class=\"row_heading level0 row11\" >MSFT</th>\n",
       "      <td id=\"T_3f2e6_row11_col0\" class=\"data row11 col0\" >1.032215</td>\n",
       "      <td id=\"T_3f2e6_row11_col1\" class=\"data row11 col1\" >0.804824</td>\n",
       "      <td id=\"T_3f2e6_row11_col2\" class=\"data row11 col2\" >0.881795</td>\n",
       "      <td id=\"T_3f2e6_row11_col3\" class=\"data row11 col3\" >1.052210</td>\n",
       "      <td id=\"T_3f2e6_row11_col4\" class=\"data row11 col4\" >0.987957</td>\n",
       "      <td id=\"T_3f2e6_row11_col5\" class=\"data row11 col5\" >1.015916</td>\n",
       "      <td id=\"T_3f2e6_row11_col6\" class=\"data row11 col6\" >0.910502</td>\n",
       "      <td id=\"T_3f2e6_row11_col7\" class=\"data row11 col7\" >0.947429</td>\n",
       "      <td id=\"T_3f2e6_row11_col8\" class=\"data row11 col8\" >1.267328</td>\n",
       "      <td id=\"T_3f2e6_row11_col9\" class=\"data row11 col9\" >0.865901</td>\n",
       "      <td id=\"T_3f2e6_row11_col10\" class=\"data row11 col10\" >1.003566</td>\n",
       "      <td id=\"T_3f2e6_row11_col11\" class=\"data row11 col11\" >0.910236</td>\n",
       "      <td id=\"T_3f2e6_row11_col12\" class=\"data row11 col12\" >1.096165</td>\n",
       "      <td id=\"T_3f2e6_row11_col13\" class=\"data row11 col13\" >0.909936</td>\n",
       "      <td id=\"T_3f2e6_row11_col14\" class=\"data row11 col14\" >0.686401</td>\n",
       "      <td id=\"T_3f2e6_row11_col15\" class=\"data row11 col15\" >0.872673</td>\n",
       "      <td id=\"T_3f2e6_row11_col16\" class=\"data row11 col16\" >0.909936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row12\" class=\"row_heading level0 row12\" >NKE</th>\n",
       "      <td id=\"T_3f2e6_row12_col0\" class=\"data row12 col0\" >0.695947</td>\n",
       "      <td id=\"T_3f2e6_row12_col1\" class=\"data row12 col1\" >0.608828</td>\n",
       "      <td id=\"T_3f2e6_row12_col2\" class=\"data row12 col2\" >0.648496</td>\n",
       "      <td id=\"T_3f2e6_row12_col3\" class=\"data row12 col3\" >0.623045</td>\n",
       "      <td id=\"T_3f2e6_row12_col4\" class=\"data row12 col4\" >0.911559</td>\n",
       "      <td id=\"T_3f2e6_row12_col5\" class=\"data row12 col5\" >1.240833</td>\n",
       "      <td id=\"T_3f2e6_row12_col6\" class=\"data row12 col6\" >1.607401</td>\n",
       "      <td id=\"T_3f2e6_row12_col7\" class=\"data row12 col7\" >0.893136</td>\n",
       "      <td id=\"T_3f2e6_row12_col8\" class=\"data row12 col8\" >0.976007</td>\n",
       "      <td id=\"T_3f2e6_row12_col9\" class=\"data row12 col9\" >1.053994</td>\n",
       "      <td id=\"T_3f2e6_row12_col10\" class=\"data row12 col10\" >1.058247</td>\n",
       "      <td id=\"T_3f2e6_row12_col11\" class=\"data row12 col11\" >1.053994</td>\n",
       "      <td id=\"T_3f2e6_row12_col12\" class=\"data row12 col12\" >0.757423</td>\n",
       "      <td id=\"T_3f2e6_row12_col13\" class=\"data row12 col13\" >1.296945</td>\n",
       "      <td id=\"T_3f2e6_row12_col14\" class=\"data row12 col14\" >1.070581</td>\n",
       "      <td id=\"T_3f2e6_row12_col15\" class=\"data row12 col15\" >1.310846</td>\n",
       "      <td id=\"T_3f2e6_row12_col16\" class=\"data row12 col16\" >1.286540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row13\" class=\"row_heading level0 row13\" >NVDA</th>\n",
       "      <td id=\"T_3f2e6_row13_col0\" class=\"data row13 col0\" >1.688845</td>\n",
       "      <td id=\"T_3f2e6_row13_col1\" class=\"data row13 col1\" >2.076737</td>\n",
       "      <td id=\"T_3f2e6_row13_col2\" class=\"data row13 col2\" >0.497619</td>\n",
       "      <td id=\"T_3f2e6_row13_col3\" class=\"data row13 col3\" >1.400347</td>\n",
       "      <td id=\"T_3f2e6_row13_col4\" class=\"data row13 col4\" >1.124511</td>\n",
       "      <td id=\"T_3f2e6_row13_col5\" class=\"data row13 col5\" >1.138686</td>\n",
       "      <td id=\"T_3f2e6_row13_col6\" class=\"data row13 col6\" >1.091795</td>\n",
       "      <td id=\"T_3f2e6_row13_col7\" class=\"data row13 col7\" >1.156391</td>\n",
       "      <td id=\"T_3f2e6_row13_col8\" class=\"data row13 col8\" >1.394650</td>\n",
       "      <td id=\"T_3f2e6_row13_col9\" class=\"data row13 col9\" >1.688845</td>\n",
       "      <td id=\"T_3f2e6_row13_col10\" class=\"data row13 col10\" >1.688845</td>\n",
       "      <td id=\"T_3f2e6_row13_col11\" class=\"data row13 col11\" >1.688845</td>\n",
       "      <td id=\"T_3f2e6_row13_col12\" class=\"data row13 col12\" >1.292219</td>\n",
       "      <td id=\"T_3f2e6_row13_col13\" class=\"data row13 col13\" >1.688845</td>\n",
       "      <td id=\"T_3f2e6_row13_col14\" class=\"data row13 col14\" >0.895698</td>\n",
       "      <td id=\"T_3f2e6_row13_col15\" class=\"data row13 col15\" >1.620534</td>\n",
       "      <td id=\"T_3f2e6_row13_col16\" class=\"data row13 col16\" >1.688845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row14\" class=\"row_heading level0 row14\" >PFE</th>\n",
       "      <td id=\"T_3f2e6_row14_col0\" class=\"data row14 col0\" >1.042641</td>\n",
       "      <td id=\"T_3f2e6_row14_col1\" class=\"data row14 col1\" >0.716187</td>\n",
       "      <td id=\"T_3f2e6_row14_col2\" class=\"data row14 col2\" >0.894264</td>\n",
       "      <td id=\"T_3f2e6_row14_col3\" class=\"data row14 col3\" >0.672112</td>\n",
       "      <td id=\"T_3f2e6_row14_col4\" class=\"data row14 col4\" >0.984625</td>\n",
       "      <td id=\"T_3f2e6_row14_col5\" class=\"data row14 col5\" >0.753015</td>\n",
       "      <td id=\"T_3f2e6_row14_col6\" class=\"data row14 col6\" >1.005529</td>\n",
       "      <td id=\"T_3f2e6_row14_col7\" class=\"data row14 col7\" >0.994814</td>\n",
       "      <td id=\"T_3f2e6_row14_col8\" class=\"data row14 col8\" >0.611372</td>\n",
       "      <td id=\"T_3f2e6_row14_col9\" class=\"data row14 col9\" >1.053392</td>\n",
       "      <td id=\"T_3f2e6_row14_col10\" class=\"data row14 col10\" >0.976248</td>\n",
       "      <td id=\"T_3f2e6_row14_col11\" class=\"data row14 col11\" >1.047515</td>\n",
       "      <td id=\"T_3f2e6_row14_col12\" class=\"data row14 col12\" >0.865884</td>\n",
       "      <td id=\"T_3f2e6_row14_col13\" class=\"data row14 col13\" >0.883926</td>\n",
       "      <td id=\"T_3f2e6_row14_col14\" class=\"data row14 col14\" >0.765359</td>\n",
       "      <td id=\"T_3f2e6_row14_col15\" class=\"data row14 col15\" >0.918949</td>\n",
       "      <td id=\"T_3f2e6_row14_col16\" class=\"data row14 col16\" >0.913543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row15\" class=\"row_heading level0 row15\" >SOFI</th>\n",
       "      <td id=\"T_3f2e6_row15_col0\" class=\"data row15 col0\" >1.815145</td>\n",
       "      <td id=\"T_3f2e6_row15_col1\" class=\"data row15 col1\" >1.269418</td>\n",
       "      <td id=\"T_3f2e6_row15_col2\" class=\"data row15 col2\" >0.659616</td>\n",
       "      <td id=\"T_3f2e6_row15_col3\" class=\"data row15 col3\" >1.097174</td>\n",
       "      <td id=\"T_3f2e6_row15_col4\" class=\"data row15 col4\" >0.910422</td>\n",
       "      <td id=\"T_3f2e6_row15_col5\" class=\"data row15 col5\" >0.622540</td>\n",
       "      <td id=\"T_3f2e6_row15_col6\" class=\"data row15 col6\" >1.081450</td>\n",
       "      <td id=\"T_3f2e6_row15_col7\" class=\"data row15 col7\" >0.900898</td>\n",
       "      <td id=\"T_3f2e6_row15_col8\" class=\"data row15 col8\" >1.065990</td>\n",
       "      <td id=\"T_3f2e6_row15_col9\" class=\"data row15 col9\" >0.863157</td>\n",
       "      <td id=\"T_3f2e6_row15_col10\" class=\"data row15 col10\" >0.692860</td>\n",
       "      <td id=\"T_3f2e6_row15_col11\" class=\"data row15 col11\" >0.807467</td>\n",
       "      <td id=\"T_3f2e6_row15_col12\" class=\"data row15 col12\" >0.599760</td>\n",
       "      <td id=\"T_3f2e6_row15_col13\" class=\"data row15 col13\" >0.632167</td>\n",
       "      <td id=\"T_3f2e6_row15_col14\" class=\"data row15 col14\" >0.513823</td>\n",
       "      <td id=\"T_3f2e6_row15_col15\" class=\"data row15 col15\" >0.707560</td>\n",
       "      <td id=\"T_3f2e6_row15_col16\" class=\"data row15 col16\" >0.687635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row16\" class=\"row_heading level0 row16\" >TSLA</th>\n",
       "      <td id=\"T_3f2e6_row16_col0\" class=\"data row16 col0\" >2.049832</td>\n",
       "      <td id=\"T_3f2e6_row16_col1\" class=\"data row16 col1\" >0.350023</td>\n",
       "      <td id=\"T_3f2e6_row16_col2\" class=\"data row16 col2\" >0.511562</td>\n",
       "      <td id=\"T_3f2e6_row16_col3\" class=\"data row16 col3\" >0.405429</td>\n",
       "      <td id=\"T_3f2e6_row16_col4\" class=\"data row16 col4\" >0.273532</td>\n",
       "      <td id=\"T_3f2e6_row16_col5\" class=\"data row16 col5\" >0.473348</td>\n",
       "      <td id=\"T_3f2e6_row16_col6\" class=\"data row16 col6\" >0.367686</td>\n",
       "      <td id=\"T_3f2e6_row16_col7\" class=\"data row16 col7\" >0.298047</td>\n",
       "      <td id=\"T_3f2e6_row16_col8\" class=\"data row16 col8\" >0.879683</td>\n",
       "      <td id=\"T_3f2e6_row16_col9\" class=\"data row16 col9\" >0.674600</td>\n",
       "      <td id=\"T_3f2e6_row16_col10\" class=\"data row16 col10\" >0.683273</td>\n",
       "      <td id=\"T_3f2e6_row16_col11\" class=\"data row16 col11\" >0.755701</td>\n",
       "      <td id=\"T_3f2e6_row16_col12\" class=\"data row16 col12\" >1.524860</td>\n",
       "      <td id=\"T_3f2e6_row16_col13\" class=\"data row16 col13\" >0.527308</td>\n",
       "      <td id=\"T_3f2e6_row16_col14\" class=\"data row16 col14\" >1.413899</td>\n",
       "      <td id=\"T_3f2e6_row16_col15\" class=\"data row16 col15\" >0.505773</td>\n",
       "      <td id=\"T_3f2e6_row16_col16\" class=\"data row16 col16\" >0.598562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row17\" class=\"row_heading level0 row17\" >UNH</th>\n",
       "      <td id=\"T_3f2e6_row17_col0\" class=\"data row17 col0\" >1.050616</td>\n",
       "      <td id=\"T_3f2e6_row17_col1\" class=\"data row17 col1\" >0.825169</td>\n",
       "      <td id=\"T_3f2e6_row17_col2\" class=\"data row17 col2\" >1.033698</td>\n",
       "      <td id=\"T_3f2e6_row17_col3\" class=\"data row17 col3\" >0.790846</td>\n",
       "      <td id=\"T_3f2e6_row17_col4\" class=\"data row17 col4\" >0.964540</td>\n",
       "      <td id=\"T_3f2e6_row17_col5\" class=\"data row17 col5\" >1.075506</td>\n",
       "      <td id=\"T_3f2e6_row17_col6\" class=\"data row17 col6\" >0.972657</td>\n",
       "      <td id=\"T_3f2e6_row17_col7\" class=\"data row17 col7\" >1.012462</td>\n",
       "      <td id=\"T_3f2e6_row17_col8\" class=\"data row17 col8\" >0.814309</td>\n",
       "      <td id=\"T_3f2e6_row17_col9\" class=\"data row17 col9\" >1.110014</td>\n",
       "      <td id=\"T_3f2e6_row17_col10\" class=\"data row17 col10\" >0.931621</td>\n",
       "      <td id=\"T_3f2e6_row17_col11\" class=\"data row17 col11\" >1.111281</td>\n",
       "      <td id=\"T_3f2e6_row17_col12\" class=\"data row17 col12\" >0.959306</td>\n",
       "      <td id=\"T_3f2e6_row17_col13\" class=\"data row17 col13\" >0.936395</td>\n",
       "      <td id=\"T_3f2e6_row17_col14\" class=\"data row17 col14\" >0.509597</td>\n",
       "      <td id=\"T_3f2e6_row17_col15\" class=\"data row17 col15\" >0.945340</td>\n",
       "      <td id=\"T_3f2e6_row17_col16\" class=\"data row17 col16\" >0.920451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row18\" class=\"row_heading level0 row18\" >WMT</th>\n",
       "      <td id=\"T_3f2e6_row18_col0\" class=\"data row18 col0\" >1.576426</td>\n",
       "      <td id=\"T_3f2e6_row18_col1\" class=\"data row18 col1\" >1.315369</td>\n",
       "      <td id=\"T_3f2e6_row18_col2\" class=\"data row18 col2\" >0.794413</td>\n",
       "      <td id=\"T_3f2e6_row18_col3\" class=\"data row18 col3\" >1.140859</td>\n",
       "      <td id=\"T_3f2e6_row18_col4\" class=\"data row18 col4\" >1.129073</td>\n",
       "      <td id=\"T_3f2e6_row18_col5\" class=\"data row18 col5\" >0.973878</td>\n",
       "      <td id=\"T_3f2e6_row18_col6\" class=\"data row18 col6\" >1.149815</td>\n",
       "      <td id=\"T_3f2e6_row18_col7\" class=\"data row18 col7\" >1.152748</td>\n",
       "      <td id=\"T_3f2e6_row18_col8\" class=\"data row18 col8\" >1.493126</td>\n",
       "      <td id=\"T_3f2e6_row18_col9\" class=\"data row18 col9\" >1.576426</td>\n",
       "      <td id=\"T_3f2e6_row18_col10\" class=\"data row18 col10\" >1.576426</td>\n",
       "      <td id=\"T_3f2e6_row18_col11\" class=\"data row18 col11\" >1.576426</td>\n",
       "      <td id=\"T_3f2e6_row18_col12\" class=\"data row18 col12\" >1.452799</td>\n",
       "      <td id=\"T_3f2e6_row18_col13\" class=\"data row18 col13\" >1.576426</td>\n",
       "      <td id=\"T_3f2e6_row18_col14\" class=\"data row18 col14\" >1.279385</td>\n",
       "      <td id=\"T_3f2e6_row18_col15\" class=\"data row18 col15\" >1.576426</td>\n",
       "      <td id=\"T_3f2e6_row18_col16\" class=\"data row18 col16\" >1.576426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f2e6_level0_row19\" class=\"row_heading level0 row19\" >XOM</th>\n",
       "      <td id=\"T_3f2e6_row19_col0\" class=\"data row19 col0\" >1.091248</td>\n",
       "      <td id=\"T_3f2e6_row19_col1\" class=\"data row19 col1\" >0.875350</td>\n",
       "      <td id=\"T_3f2e6_row19_col2\" class=\"data row19 col2\" >1.276171</td>\n",
       "      <td id=\"T_3f2e6_row19_col3\" class=\"data row19 col3\" >0.967064</td>\n",
       "      <td id=\"T_3f2e6_row19_col4\" class=\"data row19 col4\" >0.899198</td>\n",
       "      <td id=\"T_3f2e6_row19_col5\" class=\"data row19 col5\" >0.928740</td>\n",
       "      <td id=\"T_3f2e6_row19_col6\" class=\"data row19 col6\" >0.881584</td>\n",
       "      <td id=\"T_3f2e6_row19_col7\" class=\"data row19 col7\" >0.890231</td>\n",
       "      <td id=\"T_3f2e6_row19_col8\" class=\"data row19 col8\" >0.997105</td>\n",
       "      <td id=\"T_3f2e6_row19_col9\" class=\"data row19 col9\" >0.996021</td>\n",
       "      <td id=\"T_3f2e6_row19_col10\" class=\"data row19 col10\" >0.999196</td>\n",
       "      <td id=\"T_3f2e6_row19_col11\" class=\"data row19 col11\" >0.996021</td>\n",
       "      <td id=\"T_3f2e6_row19_col12\" class=\"data row19 col12\" >0.878759</td>\n",
       "      <td id=\"T_3f2e6_row19_col13\" class=\"data row19 col13\" >0.950483</td>\n",
       "      <td id=\"T_3f2e6_row19_col14\" class=\"data row19 col14\" >1.033953</td>\n",
       "      <td id=\"T_3f2e6_row19_col15\" class=\"data row19 col15\" >1.025731</td>\n",
       "      <td id=\"T_3f2e6_row19_col16\" class=\"data row19 col16\" >0.950483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2437d42c640>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOT IN USE. REMOVE EXPANDING WINDOW\n",
    "\n",
    "# Concatenate them side by side\n",
    "merged_df = pd.concat([styled_df_roll2, styled_df_roll3, styled_df_exp2, styled_df_exp3], axis=1)\n",
    "\n",
    "cols_to_drop = ['Benchmark_Roll_3', 'Benchmark_Exp_2', 'Benchmark_Exp_3']  # replace with your actual column names\n",
    "merged_df = merged_df.drop(columns=cols_to_drop)\n",
    "\n",
    "mask = merged_df.eq(merged_df.max(axis=1), axis=0)\n",
    "\n",
    "# Drop columns that are never the max in any row\n",
    "cols_to_keep = mask.any(axis=0)\n",
    "merged_df = merged_df.loc[:, cols_to_keep]\n",
    "\n",
    "\n",
    "merged_df = merged_df.style.apply(highlight_max_row, axis=1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e1f3f",
   "metadata": {},
   "source": [
    "NKE PFE BA UNH |AMZN XOM | KO | CVX JNJ| MCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf7a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
